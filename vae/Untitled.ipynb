{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "loYvRpPJzwMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "48dddca5-83e7-4c55-c519-afcaad7fd565"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x587d4000 @  0x7f3830f1f2a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Omw73GICzbgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "import struct\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qPdPA-4Dzbgn",
        "colab_type": "code",
        "outputId": "c7505222-3351-4a43-bc7a-a5ebdb385c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", \"train_features.gz\")\n",
        "urllib.request.urlretrieve(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", \"test_features.gz\")\n",
        "\n",
        "\n",
        "def get_features(filename):\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
        "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
        "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n",
        "    \n",
        "def plot_image(image):\n",
        "    plt.imshow(image.reshape((28,28)), cmap=\"gray\")\n",
        "    \n",
        "features = get_features(\"train_features.gz\").reshape((60000, 1,28,28)) / 255\n",
        "features = torch.from_numpy(features).float().cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-2AC42U-0jkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VAE, self).__init__()\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    #encoder\n",
        "    self.e_cnn1 = nn.Conv2d(1,1,(3,3))\n",
        "    self.e_cnn2 = nn.Conv2d(1,1,(3,3))\n",
        "    self.e_cnn3 = nn.Conv2d(1,1,(3,3))\n",
        "    self.e_dense_mean = nn.Linear(484, 30)\n",
        "    \n",
        "    #decoder\n",
        "    self.d_dense = nn.Linear(30,484)\n",
        "    self.d_decnn1 = nn.ConvTranspose2d(1,1,(3,3))\n",
        "    self.d_decnn2 = nn.ConvTranspose2d(1,1,(3,3))\n",
        "    self.d_decnn3 = nn.ConvTranspose2d(1,1,(3,3))\n",
        "    \n",
        "  \n",
        "  def forward(self, input, generating=False):\n",
        "    # encoding\n",
        "    mean, var = None, None\n",
        "    if not generating: \n",
        "      res = self.relu(self.e_cnn1(input))\n",
        "      res = self.relu(self.e_cnn2(res))\n",
        "      res = self.relu(self.e_cnn3(res))\n",
        "      res = res.reshape(input.shape[0], 484)\n",
        "      mean = self.relu(self.e_dense_mean(res))\n",
        "      samples = torch.randn_like(mean)\n",
        "      input = mean + samples\n",
        "    \n",
        "    # decoding\n",
        "    res = self.relu(self.d_dense(input))\n",
        "    res = res.reshape(input.shape[0], 1 , 22, 22)\n",
        "    res = self.relu(self.d_decnn1(res))\n",
        "    res = self.relu(self.d_decnn2(res))\n",
        "    res = self.sigmoid(self.d_decnn3(res))\n",
        "    return (res,mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlGtQyrM-4kN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = VAE().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDj3o1UI_D2K",
        "colab_type": "code",
        "outputId": "ac8a4a2a-b059-4091-b811-f9b067405489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4998
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "for i in range(epochs):\n",
        "  generated, mean = net(features)\n",
        "  loss_reconstruct = (((features - generated) ** 2)).sum() / 60000\n",
        "  loss_KL = mean.pow(2).sum() * 0.005 /60000\n",
        "  loss = (loss_reconstruct + loss_KL)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(\"epoch: \", i)\n",
        "  print(\"reconstruct loss: \", loss_reconstruct.item())\n",
        "  print(\"KL: \", loss_KL.item())\n",
        "  print(\"___________\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "reconstruct loss:  198.1804962158203\n",
            "KL:  0.00011291839473415166\n",
            "___________\n",
            "epoch:  1\n",
            "reconstruct loss:  197.7943572998047\n",
            "KL:  0.00014345782983582467\n",
            "___________\n",
            "epoch:  2\n",
            "reconstruct loss:  197.4279022216797\n",
            "KL:  0.00022335008543450385\n",
            "___________\n",
            "epoch:  3\n",
            "reconstruct loss:  197.06854248046875\n",
            "KL:  0.0003603340592235327\n",
            "___________\n",
            "epoch:  4\n",
            "reconstruct loss:  196.71388244628906\n",
            "KL:  0.0005672809202224016\n",
            "___________\n",
            "epoch:  5\n",
            "reconstruct loss:  196.36245727539062\n",
            "KL:  0.0008618477149866521\n",
            "___________\n",
            "epoch:  6\n",
            "reconstruct loss:  196.01177978515625\n",
            "KL:  0.0012641028733924031\n",
            "___________\n",
            "epoch:  7\n",
            "reconstruct loss:  195.6618194580078\n",
            "KL:  0.0017958335811272264\n",
            "___________\n",
            "epoch:  8\n",
            "reconstruct loss:  195.3141632080078\n",
            "KL:  0.0024821353144943714\n",
            "___________\n",
            "epoch:  9\n",
            "reconstruct loss:  194.96722412109375\n",
            "KL:  0.0033464173320680857\n",
            "___________\n",
            "epoch:  10\n",
            "reconstruct loss:  194.62088012695312\n",
            "KL:  0.0043984269723296165\n",
            "___________\n",
            "epoch:  11\n",
            "reconstruct loss:  194.2762451171875\n",
            "KL:  0.00560193182900548\n",
            "___________\n",
            "epoch:  12\n",
            "reconstruct loss:  193.9322509765625\n",
            "KL:  0.006803441792726517\n",
            "___________\n",
            "epoch:  13\n",
            "reconstruct loss:  193.5892333984375\n",
            "KL:  0.007776368409395218\n",
            "___________\n",
            "epoch:  14\n",
            "reconstruct loss:  193.246337890625\n",
            "KL:  0.00840721931308508\n",
            "___________\n",
            "epoch:  15\n",
            "reconstruct loss:  192.90513610839844\n",
            "KL:  0.008698427118360996\n",
            "___________\n",
            "epoch:  16\n",
            "reconstruct loss:  192.5655975341797\n",
            "KL:  0.00869451742619276\n",
            "___________\n",
            "epoch:  17\n",
            "reconstruct loss:  192.22817993164062\n",
            "KL:  0.00845057051628828\n",
            "___________\n",
            "epoch:  18\n",
            "reconstruct loss:  191.8917694091797\n",
            "KL:  0.008023837581276894\n",
            "___________\n",
            "epoch:  19\n",
            "reconstruct loss:  191.55697631835938\n",
            "KL:  0.007469733711332083\n",
            "___________\n",
            "epoch:  20\n",
            "reconstruct loss:  191.2252197265625\n",
            "KL:  0.006837898399680853\n",
            "___________\n",
            "epoch:  21\n",
            "reconstruct loss:  190.8946075439453\n",
            "KL:  0.006170719396322966\n",
            "___________\n",
            "epoch:  22\n",
            "reconstruct loss:  190.5675048828125\n",
            "KL:  0.0055006928741931915\n",
            "___________\n",
            "epoch:  23\n",
            "reconstruct loss:  190.2421417236328\n",
            "KL:  0.0048509822227060795\n",
            "___________\n",
            "epoch:  24\n",
            "reconstruct loss:  189.92001342773438\n",
            "KL:  0.004237858112901449\n",
            "___________\n",
            "epoch:  25\n",
            "reconstruct loss:  189.60047912597656\n",
            "KL:  0.0036727609112858772\n",
            "___________\n",
            "epoch:  26\n",
            "reconstruct loss:  189.2832489013672\n",
            "KL:  0.003161905100569129\n",
            "___________\n",
            "epoch:  27\n",
            "reconstruct loss:  188.9703369140625\n",
            "KL:  0.002707522828131914\n",
            "___________\n",
            "epoch:  28\n",
            "reconstruct loss:  188.6590118408203\n",
            "KL:  0.0023083763662725687\n",
            "___________\n",
            "epoch:  29\n",
            "reconstruct loss:  188.35162353515625\n",
            "KL:  0.0019606708083301783\n",
            "___________\n",
            "epoch:  30\n",
            "reconstruct loss:  188.04812622070312\n",
            "KL:  0.0016584965633228421\n",
            "___________\n",
            "epoch:  31\n",
            "reconstruct loss:  187.7474822998047\n",
            "KL:  0.001396605628542602\n",
            "___________\n",
            "epoch:  32\n",
            "reconstruct loss:  187.4514617919922\n",
            "KL:  0.0011696495348587632\n",
            "___________\n",
            "epoch:  33\n",
            "reconstruct loss:  187.158447265625\n",
            "KL:  0.0009739555534906685\n",
            "___________\n",
            "epoch:  34\n",
            "reconstruct loss:  186.87014770507812\n",
            "KL:  0.0008057780796661973\n",
            "___________\n",
            "epoch:  35\n",
            "reconstruct loss:  186.58558654785156\n",
            "KL:  0.0006617032340727746\n",
            "___________\n",
            "epoch:  36\n",
            "reconstruct loss:  186.30560302734375\n",
            "KL:  0.000538729305844754\n",
            "___________\n",
            "epoch:  37\n",
            "reconstruct loss:  186.06723022460938\n",
            "KL:  0.00043427999480627477\n",
            "___________\n",
            "epoch:  38\n",
            "reconstruct loss:  185.8392333984375\n",
            "KL:  0.0003461343876551837\n",
            "___________\n",
            "epoch:  39\n",
            "reconstruct loss:  185.61489868164062\n",
            "KL:  0.0002724172081798315\n",
            "___________\n",
            "epoch:  40\n",
            "reconstruct loss:  185.39295959472656\n",
            "KL:  0.00021158829622436315\n",
            "___________\n",
            "epoch:  41\n",
            "reconstruct loss:  185.1742401123047\n",
            "KL:  0.000162409502081573\n",
            "___________\n",
            "epoch:  42\n",
            "reconstruct loss:  184.95684814453125\n",
            "KL:  0.0001239126140717417\n",
            "___________\n",
            "epoch:  43\n",
            "reconstruct loss:  184.74197387695312\n",
            "KL:  9.53574271989055e-05\n",
            "___________\n",
            "epoch:  44\n",
            "reconstruct loss:  184.52877807617188\n",
            "KL:  8.246259676525369e-05\n",
            "___________\n",
            "epoch:  45\n",
            "reconstruct loss:  184.3166046142578\n",
            "KL:  7.761840970488265e-05\n",
            "___________\n",
            "epoch:  46\n",
            "reconstruct loss:  184.10595703125\n",
            "KL:  7.475282473023981e-05\n",
            "___________\n",
            "epoch:  47\n",
            "reconstruct loss:  183.8956298828125\n",
            "KL:  7.347841892624274e-05\n",
            "___________\n",
            "epoch:  48\n",
            "reconstruct loss:  183.6863555908203\n",
            "KL:  7.349261431954801e-05\n",
            "___________\n",
            "epoch:  49\n",
            "reconstruct loss:  183.4775848388672\n",
            "KL:  7.453206490026787e-05\n",
            "___________\n",
            "epoch:  50\n",
            "reconstruct loss:  183.26905822753906\n",
            "KL:  7.63653515605256e-05\n",
            "___________\n",
            "epoch:  51\n",
            "reconstruct loss:  183.060791015625\n",
            "KL:  7.880276098148897e-05\n",
            "___________\n",
            "epoch:  52\n",
            "reconstruct loss:  182.8526611328125\n",
            "KL:  8.169563807314262e-05\n",
            "___________\n",
            "epoch:  53\n",
            "reconstruct loss:  182.6446990966797\n",
            "KL:  8.493295172229409e-05\n",
            "___________\n",
            "epoch:  54\n",
            "reconstruct loss:  182.43653869628906\n",
            "KL:  8.843479736242443e-05\n",
            "___________\n",
            "epoch:  55\n",
            "reconstruct loss:  182.2284698486328\n",
            "KL:  9.21469836612232e-05\n",
            "___________\n",
            "epoch:  56\n",
            "reconstruct loss:  182.0203399658203\n",
            "KL:  9.603225771570578e-05\n",
            "___________\n",
            "epoch:  57\n",
            "reconstruct loss:  181.8119354248047\n",
            "KL:  0.00010006415686802939\n",
            "___________\n",
            "epoch:  58\n",
            "reconstruct loss:  181.60328674316406\n",
            "KL:  0.00010422033665236086\n",
            "___________\n",
            "epoch:  59\n",
            "reconstruct loss:  181.39463806152344\n",
            "KL:  0.00010848095553228632\n",
            "___________\n",
            "epoch:  60\n",
            "reconstruct loss:  181.18551635742188\n",
            "KL:  0.00011282855120953172\n",
            "___________\n",
            "epoch:  61\n",
            "reconstruct loss:  180.9763641357422\n",
            "KL:  0.0001172466145362705\n",
            "___________\n",
            "epoch:  62\n",
            "reconstruct loss:  180.76693725585938\n",
            "KL:  0.00012172183051006868\n",
            "___________\n",
            "epoch:  63\n",
            "reconstruct loss:  180.55735778808594\n",
            "KL:  0.0001262438454432413\n",
            "___________\n",
            "epoch:  64\n",
            "reconstruct loss:  180.34747314453125\n",
            "KL:  0.00013080346980132163\n",
            "___________\n",
            "epoch:  65\n",
            "reconstruct loss:  180.13722229003906\n",
            "KL:  0.00013539135397877544\n",
            "___________\n",
            "epoch:  66\n",
            "reconstruct loss:  179.92694091796875\n",
            "KL:  0.00013999843213241547\n",
            "___________\n",
            "epoch:  67\n",
            "reconstruct loss:  179.71632385253906\n",
            "KL:  0.0001446159149054438\n",
            "___________\n",
            "epoch:  68\n",
            "reconstruct loss:  179.50564575195312\n",
            "KL:  0.00014923526032362133\n",
            "___________\n",
            "epoch:  69\n",
            "reconstruct loss:  179.29458618164062\n",
            "KL:  0.0001538486685603857\n",
            "___________\n",
            "epoch:  70\n",
            "reconstruct loss:  179.0834197998047\n",
            "KL:  0.0001584486453793943\n",
            "___________\n",
            "epoch:  71\n",
            "reconstruct loss:  178.87208557128906\n",
            "KL:  0.00016302838048432022\n",
            "___________\n",
            "epoch:  72\n",
            "reconstruct loss:  178.6605987548828\n",
            "KL:  0.00016758164565544575\n",
            "___________\n",
            "epoch:  73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4MQ1VkarAToj",
        "colab_type": "code",
        "outputId": "cde0e2e8-9a93-4934-dee2-d94467efa5cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "NSS5S2uPLGXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def plot_image(image):\n",
        "    plt.imshow(image.detach().cpu().numpy().reshape((28,28)) * 255, cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J_VPsWN3LU72",
        "colab_type": "code",
        "outputId": "dbffc23d-9b47-4604-88e0-cb0d72f8163a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "sample = net(torch.randn(100).cuda(), generating=True)[0]\n",
        "plot_image(sample)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3fb8decfd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Eofqr0w5ZoNu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}